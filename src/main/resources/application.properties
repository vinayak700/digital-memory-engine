# ==================================================
# Application
# ==================================================
spring.application.name=digital-memory-engine
server.port=8082

# ==================================================
# Gemini AI
# ==================================================
gemini.api.key=${GEMINI_API_KEY:AIzaSyCrEAr6ahTctWbCbDscKsE6d9APOOTLxVA}
gemini.api.url=https://generativelanguage.googleapis.com/v1beta/models/gemini-flash-latest:generateContent

# ==================================================
# PostgreSQL (Supabase - Session Pooler)
# ==================================================
spring.datasource.url=${DB_URL:jdbc:postgresql://aws-1-ap-south-1.pooler.supabase.com:5432/postgres?sslmode=require}
spring.datasource.username=${DB_USERNAME:postgres.sbuuypbdqflrzulqxnsc}
spring.datasource.password=${DB_PASSWORD:db@_Postgres}
spring.datasource.driver-class-name=org.postgresql.Driver

# Connection pool settings
spring.datasource.hikari.maximum-pool-size=3
spring.datasource.hikari.minimum-idle=2
spring.datasource.hikari.connection-timeout=30000
spring.datasource.hikari.idle-timeout=300000
spring.datasource.hikari.max-lifetime=540000
spring.datasource.hikari.connection-init-sql=SELECT 1
spring.datasource.hikari.validation-timeout=5000

# ==================================================
# JPA / Hibernate
# ==================================================
spring.jpa.hibernate.ddl-auto=validate
spring.jpa.open-in-view=false
spring.jpa.show-sql=false
spring.jpa.properties.hibernate.format_sql=true
spring.jpa.properties.hibernate.jdbc.time_zone=UTC
spring.jpa.properties.hibernate.default_schema=public
spring.jpa.defer-datasource-initialization=false

# ==================================================
# Flyway Database Migrations
# ==================================================
spring.flyway.baseline-on-migrate=true
spring.flyway.locations=classpath:db/migration
spring.flyway.schemas=public
spring.flyway.baseline-version=0
spring.flyway.baseline-description=Initial baseline
spring.flyway.validate-on-migrate=false
spring.flyway.clean-disabled=true
spring.flyway.table=flyway_schema_history
spring.flyway.enabled=true
spring.flyway.repair-on-migrate=true

# ==================================================
# Actuator / Monitoring
# ==================================================
management.endpoints.web.exposure.include=health,info,metrics
management.endpoint.health.show-details=always

# ==================================================
# Security
# ==================================================
# Security now handled via DB (V3 migration) and SecurityConfig
# Default admin: admin / admin123


# ==================================================
# Logging
# ==================================================
logging.level.root=${LOG_LEVEL_ROOT:INFO}
logging.level.org.springframework.web=INFO
logging.level.org.hibernate.SQL=${LOG_LEVEL_HIBERNATE:INFO}
logging.level.org.flywaydb=INFO
logging.level.com.memory.context.engine=${LOG_LEVEL_APP:INFO}

# ==================================================
# Redis (Upstash)
# ==================================================
spring.data.redis.host=${REDIS_HOST:funny-pipefish-29455.upstash.io}
spring.data.redis.port=${REDIS_PORT:6379}
spring.data.redis.password=${REDIS_PASSWORD:AXMPAAIncDIxMTg5OGQwMWFkYmY0MTdmODhkNjhjOWUwZjMwOTQyN3AyMjk0NTU}
spring.data.redis.ssl.enabled=true

# ==================================================
# Semantic Cache (Intelligent Fuzzy Matching)
# ==================================================
semantic.cache.enabled=true
semantic.cache.similarity-threshold=0.60
semantic.cache.ttl-minutes=60
semantic.cache.l1-max-size=1000

# ==================================================
# Kafka (Confluent Cloud)
# NOTE: Replace BOOTSTRAP_SERVER with your Confluent Cloud bootstrap URL
# ==================================================
spring.kafka.bootstrap-servers=pkc-l7pr2.ap-south-1.aws.confluent.cloud:9092
spring.kafka.consumer.group-id=memory-engine-group
spring.kafka.consumer.auto-offset-reset=latest
spring.kafka.consumer.key-deserializer=org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
spring.kafka.consumer.properties.spring.deserializer.key.delegate.class=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.properties.spring.deserializer.value.delegate.class=org.springframework.kafka.support.serializer.JsonDeserializer
spring.kafka.consumer.properties.spring.json.trusted.packages=*
spring.kafka.consumer.properties.spring.json.use.type.headers=false
spring.kafka.consumer.properties.spring.json.value.default.type=com.memory.context.engine.domain.memory.event.MemoryDomainEvent
spring.kafka.producer.acks=all

# Confluent Cloud SASL/SSL Authentication
spring.kafka.properties.security.protocol=SASL_SSL
spring.kafka.properties.sasl.mechanism=PLAIN
spring.kafka.properties.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="${KAFKA_USER:LJWPBIKCTNOCURSW}" password="${KAFKA_PASSWORD:cfltZy745x9SXpQx6VVGlZVM/zjpnZsh8jBR+DWK7ACdn8+xVNuOEDShi/Hu2Qzw}";

# Confluent Cloud specific settings
spring.kafka.properties.ssl.endpoint.identification.algorithm=https
spring.kafka.properties.client.dns.lookup=use_all_dns_ips
spring.kafka.properties.session.timeout.ms=45000